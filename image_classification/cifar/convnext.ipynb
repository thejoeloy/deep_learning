{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc5adb41-8ddd-402f-8087-f1d610967fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to /home/eagle/Projects/dl_from_scratch/cifar10/cifar-100-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████| 169001437/169001437 [00:02<00:00, 65443124.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /home/eagle/Projects/dl_from_scratch/cifar10/cifar-100-python.tar.gz to /home/eagle/Projects/dl_from_scratch/cifar10\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomRotation(degrees=15),  # Randomly rotate the image by up to 15 degrees\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),  # Randomly translate the image\n",
    "    #transforms.RandomResizedCrop(size=28, scale=(0.8, 1.0)),  # Randomly crop and resize\n",
    "    #transforms.ColorJitter(brightness=0.1, contrast=0.1),  # Random brightness and contrast\n",
    "    transforms.ToTensor(),  # Convert images to tensors\n",
    "    transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)) \n",
    "])\n",
    "\n",
    "train_ds = torchvision.datasets.CIFAR100(\"/home/eagle/Projects/dl_from_scratch/cifar10\", train=True, download=True, transform=transform)\n",
    "test_ds = torchvision.datasets.CIFAR100(\"/home/eagle/Projects/dl_from_scratch/cifar10\", train=False, download=True, transform=transform)\n",
    "\n",
    "train_size = int(0.8 * len(train_ds))  # 80% for training\n",
    "val_size = len(train_ds) - train_size  # 20% for validation\n",
    "\n",
    "# Split the train_dataset into train and val\n",
    "train_ds, val_ds = random_split(train_ds, [train_size, val_size])\n",
    "\n",
    "batch_size = 512\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=6)\n",
    "val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=6)\n",
    "test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0be2753c-20b7-4668-85aa-a7f5be535ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([1, 1000])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ConvNextBlock(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel):\n",
    "        super(ConvNextBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=in_channel, out_channels=in_channel, kernel_size=7, padding=3, groups=in_channel)\n",
    "        self.ln1 = nn.LayerNorm(in_channel)\n",
    "        self.conv2 = nn.Conv2d(in_channels=in_channel, out_channels= 4 * in_channel, kernel_size=1)\n",
    "        self.gelu = nn.GELU()\n",
    "        self.conv3 = nn.Conv2d(in_channels=4 * in_channel, out_channels=out_channel, kernel_size=1)\n",
    "        self.ls1 = LayerScale(out_channel)\n",
    "        self.dp1 = DropPath() \n",
    "            \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = self.conv1(x)\n",
    "        x = x.permute(0, 2, 3, 1)\n",
    "        x = self.ln1(x)\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "        x = self.conv2(x)\n",
    "        x = self.gelu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.ls1(x)\n",
    "        x = self.dp1(x)\n",
    "        x += residual\n",
    "        return x\n",
    "\n",
    "class LayerScale(nn.Module):\n",
    "    def __init__(self, channels, init_value=1e-6):\n",
    "        super(LayerScale, self).__init__()\n",
    "        self.gamma = nn.Parameter(init_value * torch.ones((1, channels, 1, 1)))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.gamma * x\n",
    "\n",
    "class DropPath(nn.Module):\n",
    "    def __init__(self, drop_prob=0.1):\n",
    "        super(DropPath, self).__init__()\n",
    "        self.drop_prob = drop_prob\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.drop_prob == 0 or not self.training:\n",
    "            return x\n",
    "        keep_prob = 1 - self.drop_prob\n",
    "        shape = (x.shape[0],) + (1,) * (x.ndim - 1)\n",
    "        random_tensor = keep_prob + torch.rand(shape, dtype=x.dtype, device=x.device)\n",
    "        random_tensor.floor()\n",
    "        return x / keep_prob * random_tensor\n",
    "\n",
    "class DownsampleBlock(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super(DownsampleBlock, self).__init__()\n",
    "        self.l1 = nn.LayerNorm(channels)\n",
    "        self.conv1 = nn.Conv2d(in_channels=channels, out_channels=channels * 2 , kernel_size=2, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 3, 1)\n",
    "        x = self.l1(x)\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "        x = self.conv1(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ConvNext(nn.Module):\n",
    "    def __init__(self, num_classes=1000):\n",
    "        super(ConvNext, self).__init__()\n",
    "\n",
    "        self.stem = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=96, kernel_size=4, stride=4),\n",
    "        )\n",
    "\n",
    "        self.stem_ln = nn.LayerNorm(96, eps=1e-6)\n",
    "\n",
    "        # Stages (following ConvNeXt Tiny/Small structure)\n",
    "        self.stage1 = self._make_stage(ConvNextBlock, in_channel=96, out_channel=96, num_blocks=3)\n",
    "        self.downsample1 = DownsampleBlock(96)\n",
    "        \n",
    "        self.stage2 = self._make_stage(ConvNextBlock, in_channel=192, out_channel=192, num_blocks=3)\n",
    "        self.downsample2 = DownsampleBlock(192)\n",
    "        \n",
    "        self.stage3 = self._make_stage(ConvNextBlock, in_channel=384, out_channel=384, num_blocks=9)\n",
    "        self.downsample3 = DownsampleBlock(384)\n",
    "        \n",
    "        self.stage4 = self._make_stage(ConvNextBlock, in_channel=768, out_channel=768, num_blocks=3)\n",
    "\n",
    "        # Classification head\n",
    "        self.norm = nn.LayerNorm(768, eps=1e-6)  # Final layer norm\n",
    "        self.fc = nn.Linear(768, num_classes)\n",
    "\n",
    "    def _make_stage(self, block, in_channel, out_channel, num_blocks):\n",
    "        layers = []\n",
    "        for _ in range(num_blocks):\n",
    "            layers.append(block(in_channel, out_channel))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.stem(x)\n",
    "\n",
    "        x = x.permute(0, 2, 3, 1)  # (batch, height, width, channels)\n",
    "        x = self.stem_ln(x)\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "        \n",
    "        x = self.stage1(x)\n",
    "        x = self.downsample1(x)\n",
    "        \n",
    "        x = self.stage2(x)\n",
    "        x = self.downsample2(x)\n",
    "        \n",
    "        x = self.stage3(x)\n",
    "        x = self.downsample3(x)\n",
    "        \n",
    "        x = self.stage4(x)\n",
    "\n",
    "        x = x.mean(dim=[2, 3])  # Global average pooling\n",
    "\n",
    "        x = self.norm(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the ConvNeXt model\n",
    "model = ConvNext(num_classes=1000) \n",
    "\n",
    "# Test with a random input tensor\n",
    "x = torch.randn(1, 3, 224, 224)\n",
    "out = model(x)\n",
    "print(\"Output shape:\", out.shape)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d4d45f-36ee-4e2c-ac37-fdb372d889f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = ConvNet().to(device)\n",
    "model.eval()\n",
    "model.fuse_model()  # Fuse the model layers\n",
    "model.train()\n",
    "#model = torch.compile(model)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-4, weight_decay=0.01)\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "num_epochs = 15\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)  \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass with mixed precision\n",
    "        with torch.cuda.amp.autocast():  \n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "\n",
    "        # Backward pass\n",
    "        scaler.scale(loss).backward()  # Scale the loss for stable gradients\n",
    "        scaler.step(optimizer)  # Update the parameters\n",
    "        scaler.update()  # Update the scaler\n",
    "\n",
    "        running_loss += loss.item()   \n",
    "        \n",
    "    # Calculate average loss for the epoch\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    running_val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient calculation\n",
    "        for inputs, labels in val_loader:  # Assuming val_loader is defined\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            with torch.cuda.amp.autocast():  # Enable autocasting for validation\n",
    "                outputs = model(inputs)\n",
    "                loss = loss_fn(outputs, labels)\n",
    "                \n",
    "            running_val_loss += loss.item()\n",
    "\n",
    "            # Calculate accuracy\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    # Calculate average validation loss and accuracy\n",
    "    avg_val_loss = running_val_loss / len(val_loader)\n",
    "    accuracy = correct / total * 100  # Convert to percentage\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], \"\n",
    "          f\"Training Loss: {avg_loss:.4f}, \"\n",
    "          f\"Validation Loss: {avg_val_loss:.4f}, \"\n",
    "          f\"Validation Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "print(\"Training complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
