{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33e0d302-be0a-435a-9220-10a97a5c8044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomRotation(degrees=15),  \n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)), \n",
    "    transforms.RandomResizedCrop(size=(32, 32), scale=(0.8, 1.0)),\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
    "    transforms.ToTensor(),  \n",
    "    transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)) \n",
    "])\n",
    "\n",
    "train_ds = torchvision.datasets.CIFAR100(\"/home/eagle/Projects/dl_from_scratch/cifar10\", train=True, download=True, transform=transform)\n",
    "test_ds = torchvision.datasets.CIFAR100(\"/home/eagle/Projects/dl_from_scratch/cifar10\", train=False, download=True, transform=transform)\n",
    "\n",
    "train_size = int(0.8 * len(train_ds))  # 80% for training\n",
    "val_size = len(train_ds) - train_size  # 20% for validation\n",
    "\n",
    "# Split the train_dataset into train and val\n",
    "train_ds, val_ds = random_split(train_ds, [train_size, val_size])\n",
    "\n",
    "batch_size = 512\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=6)\n",
    "val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=6)\n",
    "test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a4d2a27-8e44-4b19-921d-839926923523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------\n",
      "                Layer (type)        Output Shape         Param #     Tr. Param #\n",
      "=================================================================================\n",
      "                    Conv2d-1      [1, 192, 8, 8]           9,408           9,408\n",
      "                   Dropout-2        [1, 65, 192]               0               0\n",
      "   TransformerEncoderLayer-3        [1, 65, 192]         341,684         341,684\n",
      "   TransformerEncoderLayer-4        [1, 65, 192]         341,684         341,684\n",
      "   TransformerEncoderLayer-5        [1, 65, 192]         341,684         341,684\n",
      "   TransformerEncoderLayer-6        [1, 65, 192]         341,684         341,684\n",
      "                 LayerNorm-7            [1, 192]             384             384\n",
      "                    Linear-8            [1, 100]          19,300          19,300\n",
      "=================================================================================\n",
      "Total params: 1,395,828\n",
      "Trainable params: 1,395,828\n",
      "Non-trainable params: 0\n",
      "---------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "from pytorch_model_summary import summary\n",
    "\n",
    "class FeedForwardBlock(nn.Module):\n",
    "    def __init__(self, d_model: int, d_ff: int, dropout: float):\n",
    "        super().__init__()\n",
    "        self.linear_1 = nn.Linear(d_model, d_ff)\n",
    "        self.gelu = nn.GELU()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear_2 = nn.Linear(d_ff, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear_2(self.dropout(self.gelu(self.linear_1(x))))\n",
    "\n",
    "class MultiHeadAttentionBlock(nn.Module):\n",
    "    def __init__(self, d_model: int, h: int, dropout: float) -> None:\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.h = h\n",
    "        assert d_model % h == 0, \"d_model is not appropriate size\"\n",
    "\n",
    "        self.d_k = d_model // h\n",
    "        self.w_q = nn.Linear(d_model, d_model)\n",
    "        self.w_k = nn.Linear(d_model, d_model)\n",
    "        self.w_v = nn.Linear(d_model, d_model)\n",
    "\n",
    "        self.w_o = nn.Linear(d_model, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    @staticmethod\n",
    "    def attention(query, key, value, mask, dropout: nn.Dropout):\n",
    "        d_k = query.shape[-1]\n",
    "\n",
    "        attention_scores = (query @ key.transpose(-2, -1)) / math.sqrt(d_k)\n",
    "        if mask is not None:\n",
    "            attention_scores.masked_fill(mask == 0, -1e9)\n",
    "        attention_scores = attention_scores.softmax(dim = -1)\n",
    "        if dropout is not None:\n",
    "            attention_scores = dropout(attention_scores)\n",
    "        return (attention_scores @ value), attention_scores\n",
    "        \n",
    "    def forward(self, q, v, k, mask):\n",
    "        query = self.w_q(q)\n",
    "        key = self.w_k(k)\n",
    "        value = self.w_v(v)\n",
    "\n",
    "        query = query.view(query.shape[0], query.shape[1], self.h, self.d_k).transpose(1, 2)\n",
    "        key = key.view(key.shape[0], key.shape[1], self.h, self.d_k).transpose(1, 2)\n",
    "        value = value.view(value.shape[0], value.shape[1], self.h, self.d_k).transpose(1, 2)\n",
    "\n",
    "        x, self_attention_scores = MultiHeadAttentionBlock.attention(query, key, value, mask, self.dropout)\n",
    "\n",
    "        x = x.transpose(1, 2).contiguous().view(x.shape[0], -1, self.h * self.d_k)\n",
    "        return self.w_o(x)\n",
    "\n",
    "class TransformerEncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, h, d_ff, dropout):\n",
    "        super().__init__()\n",
    "        self.attention = MultiHeadAttentionBlock(d_model, h, dropout)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.ff = FeedForwardBlock(d_model, d_ff, dropout)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        x = x + self.attention(self.norm1(x), self.norm1(x), self.norm1(x), mask)\n",
    "        x = x + self.ff(self.norm2(x))\n",
    "        return x\n",
    "\n",
    "class DEIT(nn.Module):\n",
    "    def __init__(self, img_size=224, patch_size=16, d_model=192, num_classes=1000, num_layers=12, h=3, d_ff=768, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.patch_size = patch_size\n",
    "        num_patches = (img_size // patch_size) ** 2\n",
    "        self.d_model = d_model\n",
    "\n",
    "        self.patch_embed = nn.Conv2d(3, d_model, kernel_size=patch_size, stride=patch_size)\n",
    "\n",
    "        self.class_token = nn.Parameter(torch.randn(1, 1, d_model))\n",
    "        self.pos_embed = nn.Parameter(torch.randn(1, num_patches + 1, d_model))\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.layers = nn.ModuleList([\n",
    "            TransformerEncoderLayer(d_model, h, d_ff, dropout)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "        self.classifier = nn.Linear(d_model, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        x = self.patch_embed(x).flatten(2).transpose(1, 2)\n",
    "\n",
    "        class_token = self.class_token.expand(batch_size, -1, -1)\n",
    "        x = torch.cat((class_token, x), dim=1)\n",
    "\n",
    "        x = x + self.pos_embed\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "\n",
    "        x = self.norm(x[:, 0])  # Only use the class token\n",
    "        return self.classifier(x)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = DEIT(img_size=32, patch_size=4, d_model=192, num_classes=100, num_layers=4, h=3, d_ff=768, dropout=0.1).to(device)\n",
    "print(summary(model, torch.zeros(1, 3, 32,32).to(device), show_input=False, show_hierarchical=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4874814-1ceb-4aad-b66d-0bd5611211d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_36921/4081820315.py:6: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n",
      "Epoch [1/100] - Training:   0%|                          | 0/79 [00:00<?, ?it/s]/tmp/ipykernel_36921/4081820315.py:22: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Validation:   0%|                                        | 0/20 [00:00<?, ?it/s]/tmp/ipykernel_36921/4081820315.py:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():  # Enable autocasting for validation\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Training Loss: 4.4306, Validation Loss: 4.2432, Validation Accuracy: 4.87%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/100], Training Loss: 4.1112, Validation Loss: 3.9193, Validation Accuracy: 10.36%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/100], Training Loss: 3.8542, Validation Loss: 3.7122, Validation Accuracy: 13.75%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/100], Training Loss: 3.6964, Validation Loss: 3.5741, Validation Accuracy: 15.87%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/100], Training Loss: 3.5691, Validation Loss: 3.4694, Validation Accuracy: 16.81%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/100], Training Loss: 3.4662, Validation Loss: 3.3724, Validation Accuracy: 18.48%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/100], Training Loss: 3.3794, Validation Loss: 3.2944, Validation Accuracy: 20.44%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/100], Training Loss: 3.3058, Validation Loss: 3.2364, Validation Accuracy: 20.93%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/100], Training Loss: 3.2428, Validation Loss: 3.1891, Validation Accuracy: 22.46%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Training Loss: 3.1788, Validation Loss: 3.1202, Validation Accuracy: 23.77%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/100], Training Loss: 3.1254, Validation Loss: 3.1185, Validation Accuracy: 23.27%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/100], Training Loss: 3.0837, Validation Loss: 3.0176, Validation Accuracy: 25.51%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/100], Training Loss: 3.0370, Validation Loss: 3.0091, Validation Accuracy: 25.20%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/100], Training Loss: 2.9970, Validation Loss: 2.9757, Validation Accuracy: 26.20%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/100], Training Loss: 2.9596, Validation Loss: 2.9391, Validation Accuracy: 27.33%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/100], Training Loss: 2.9241, Validation Loss: 2.9250, Validation Accuracy: 27.57%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/100], Training Loss: 2.8833, Validation Loss: 2.8949, Validation Accuracy: 27.67%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/100], Training Loss: 2.8562, Validation Loss: 2.8545, Validation Accuracy: 28.85%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/100], Training Loss: 2.8208, Validation Loss: 2.8431, Validation Accuracy: 28.71%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/100], Training Loss: 2.7932, Validation Loss: 2.8201, Validation Accuracy: 29.15%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/100], Training Loss: 2.7704, Validation Loss: 2.8044, Validation Accuracy: 30.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/100], Training Loss: 2.7427, Validation Loss: 2.7887, Validation Accuracy: 30.10%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/100], Training Loss: 2.7276, Validation Loss: 2.7508, Validation Accuracy: 30.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/100], Training Loss: 2.6950, Validation Loss: 2.7499, Validation Accuracy: 30.36%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/100], Training Loss: 2.6673, Validation Loss: 2.7370, Validation Accuracy: 31.01%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/100], Training Loss: 2.6381, Validation Loss: 2.7259, Validation Accuracy: 31.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/100], Training Loss: 2.6163, Validation Loss: 2.7024, Validation Accuracy: 31.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/100], Training Loss: 2.6054, Validation Loss: 2.6784, Validation Accuracy: 32.34%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/100], Training Loss: 2.5718, Validation Loss: 2.6699, Validation Accuracy: 32.61%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/100], Training Loss: 2.5569, Validation Loss: 2.6556, Validation Accuracy: 32.66%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/100], Training Loss: 2.5274, Validation Loss: 2.6447, Validation Accuracy: 33.52%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/100], Training Loss: 2.5127, Validation Loss: 2.6305, Validation Accuracy: 33.33%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/100], Training Loss: 2.4874, Validation Loss: 2.6166, Validation Accuracy: 33.66%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/100], Training Loss: 2.4712, Validation Loss: 2.6186, Validation Accuracy: 33.56%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/100], Training Loss: 2.4462, Validation Loss: 2.6092, Validation Accuracy: 34.29%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 28\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Backward pass\u001b[39;00m\n\u001b[1;32m     27\u001b[0m scaler\u001b[38;5;241m.\u001b[39mscale(loss)\u001b[38;5;241m.\u001b[39mbackward()  \u001b[38;5;66;03m# Scale the loss for stable gradients\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m scaler\u001b[38;5;241m.\u001b[39mstep(optimizer)  \u001b[38;5;66;03m# Update the parameters\u001b[39;00m\n\u001b[1;32m     29\u001b[0m scaler\u001b[38;5;241m.\u001b[39mupdate()  \u001b[38;5;66;03m# Update the scaler\u001b[39;00m\n\u001b[1;32m     31\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()   \n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/amp/grad_scaler.py:454\u001b[0m, in \u001b[0;36mGradScaler.step\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munscale_(optimizer)\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;28mlen\u001b[39m(optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    452\u001b[0m ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo inf checks were recorded for this optimizer.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 454\u001b[0m retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_opt_step(optimizer, optimizer_state, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    456\u001b[0m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstage\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m OptState\u001b[38;5;241m.\u001b[39mSTEPPED\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/amp/grad_scaler.py:351\u001b[0m, in \u001b[0;36mGradScaler._maybe_opt_step\u001b[0;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_maybe_opt_step\u001b[39m(\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    345\u001b[0m     optimizer: torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mOptimizer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    349\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[1;32m    350\u001b[0m     retval: Optional[\u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 351\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28msum\u001b[39m(v\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    352\u001b[0m         retval \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mstep(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    353\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/amp/grad_scaler.py:351\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_maybe_opt_step\u001b[39m(\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    345\u001b[0m     optimizer: torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mOptimizer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    349\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[1;32m    350\u001b[0m     retval: Optional[\u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 351\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28msum\u001b[39m(v\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    352\u001b[0m         retval \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mstep(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    353\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-4, weight_decay=0.01)\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "num_epochs = 100\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    # Add tqdm to the training loop\n",
    "    train_loader_tqdm = tqdm(train_loader, desc=f\"Epoch [{epoch + 1}/{num_epochs}] - Training\", leave=False)\n",
    "    \n",
    "    for inputs, labels in train_loader_tqdm:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)  \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass with mixed precision\n",
    "        with torch.cuda.amp.autocast():  \n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "\n",
    "        # Backward pass\n",
    "        scaler.scale(loss).backward()  # Scale the loss for stable gradients\n",
    "        scaler.step(optimizer)  # Update the parameters\n",
    "        scaler.update()  # Update the scaler\n",
    "\n",
    "        running_loss += loss.item()   \n",
    "        \n",
    "        # Update tqdm description with running loss\n",
    "        train_loader_tqdm.set_postfix(loss=loss.item())\n",
    "\n",
    "    # Calculate average loss for the epoch\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    running_val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    # Add tqdm to the validation loop\n",
    "    val_loader_tqdm = tqdm(val_loader, desc=\"Validation\", leave=False)\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient calculation\n",
    "        for inputs, labels in val_loader_tqdm:  # Assuming val_loader is defined\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            with torch.cuda.amp.autocast():  # Enable autocasting for validation\n",
    "                outputs = model(inputs)\n",
    "                loss = loss_fn(outputs, labels)\n",
    "                \n",
    "            running_val_loss += loss.item()\n",
    "\n",
    "            # Calculate accuracy\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            # Update tqdm description with running validation loss\n",
    "            val_loader_tqdm.set_postfix(val_loss=loss.item())\n",
    "    \n",
    "    # Calculate average validation loss and accuracy\n",
    "    avg_val_loss = running_val_loss / len(val_loader)\n",
    "    accuracy = correct / total * 100  # Convert to percentage\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], \"\n",
    "          f\"Training Loss: {avg_loss:.4f}, \"\n",
    "          f\"Validation Loss: {avg_val_loss:.4f}, \"\n",
    "          f\"Validation Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1935ccf7-28cf-438f-94e4-ee720a358cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()  # Set the model to evaluation mode\n",
    "running_test_loss = 0.0\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# Add tqdm to the test loop\n",
    "test_loader_tqdm = tqdm(test_loader, desc=\"Testing\", leave=False)\n",
    "\n",
    "with torch.no_grad():  # Disable gradient calculation\n",
    "    for inputs, labels in test_loader_tqdm:  # Assuming test_loader is defined\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        with torch.cuda.amp.autocast():  # Enable autocasting for testing\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "        \n",
    "        running_test_loss += loss.item()\n",
    "\n",
    "        # Calculate accuracy\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        # Update tqdm description with running test loss\n",
    "        test_loader_tqdm.set_postfix(test_loss=loss.item())\n",
    "\n",
    "# Calculate average test loss and accuracy\n",
    "avg_test_loss = running_test_loss / len(test_loader)\n",
    "test_accuracy = correct / total * 100  # Convert to percentage\n",
    "\n",
    "print(f\"Test Loss: {avg_test_loss:.4f}, \"\n",
    "      f\"Test Accuracy: {test_accuracy:.2f}%\")\n",
    "\n",
    "print(\"Testing complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
